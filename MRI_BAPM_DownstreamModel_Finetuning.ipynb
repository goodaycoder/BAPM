{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edfe0e95-06d4-4487-b45e-290abac2c555",
   "metadata": {},
   "source": [
    "<a href=\"https://mingxia.web.unc.edu/\" target=\"_parent\"><img src=\"https://mingxia.web.unc.edu/wp-content/uploads/sites/12411/2020/12/logo_MagicLab-horizontal-4.png\" alt=\"MAGIC Lab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22493e6f-93c8-41c9-91d1-6e23191a7e81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **BAPM Downstream Model Finetuning on CID vs. CND Classification**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ca9df7-5fd3-4c39-b21d-2874094f870e",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Loading required libraries**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f754556f-f4f9-4c5e-a62c-832c7879fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "import sys, argparse\n",
    "import enum\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import json\n",
    "import multiprocessing\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pylab as pl\n",
    "import logging\n",
    "import shutil\n",
    "import tempfile\n",
    "import gzip\n",
    "from typing import Optional, Sequence, Tuple, Union\n",
    "from urllib.request import urlretrieve\n",
    "from PIL import Image\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from IPython import display\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import copy\n",
    "import pprint\n",
    "import torchio as tio\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import L1Loss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_auc_score, matthews_corrcoef\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm\n",
    "\n",
    "from neuroCombat import neuroCombat\n",
    "\n",
    "\n",
    "import monai\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, ImageDataset\n",
    "from monai.networks.nets import VarAutoEncoder,ViTAutoEnc, AutoEncoder\n",
    "from monai.networks.layers.convutils import calculate_out_shape, same_padding\n",
    "from monai.networks.layers.factories import Act, Norm\n",
    "from monai.utils import set_determinism, first\n",
    "from monai.utils.enums import MetricReduction\n",
    "from monai.metrics import compute_hausdorff_distance, HausdorffDistanceMetric\n",
    "from monai.losses import ContrastiveLoss, DiceLoss, DiceCELoss\n",
    "from monai.transforms import (\n",
    "    ConvertToMultiChannelBasedOnBratsClasses,\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    "    AddChannelD,\n",
    "    Compose,\n",
    "    LoadImageD,\n",
    "    ScaleIntensityD,\n",
    "    EnsureTypeD,\n",
    "    LoadImaged,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    CopyItemsd,\n",
    "    SpatialPadd,\n",
    "    EnsureChannelFirstd,\n",
    "    Spacingd,\n",
    "    OneOf,\n",
    "    ScaleIntensityRanged,\n",
    "    RandSpatialCropSamplesd,\n",
    "    RandCoarseDropoutd,\n",
    "    RandCoarseShuffled\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295062b-9ce3-40c4-b301-05c4a668aeb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Global Setting**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945f383c-0a8a-4d77-96d8-8e369159da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "set_determinism(seed=0)\n",
    "pin_memory = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "pretrained_path = './pretrained/'\n",
    "trained_path = './models/'\n",
    "logdir_path = os.path.normpath('./log/')\n",
    "if os.path.exists(logdir_path)==False:\n",
    "    os.mkdir(logdir_path)\n",
    "if os.path.exists(pretrained_path)==False:\n",
    "    os.mkdir(pretrained_path)\n",
    "if os.path.exists(trained_path)==False:\n",
    "    os.mkdir(trained_path)\n",
    "modelname = 'AEclf';\n",
    "pretrained = False\n",
    "downsampled = False\n",
    "samplespace = 1\n",
    "if downsampled:\n",
    "    samplespace = 2 #2,4,8\n",
    "max_epochs = 2\n",
    "val_interval = 2\n",
    "kfold = 5\n",
    "categories = 2\n",
    "Combat = False\n",
    "if pretrained:\n",
    "    savedir = trained_path+'Pretrained_'\n",
    "else:\n",
    "    savedir = trained_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b2035-122a-480f-af93-cbc105ff3fe6",
   "metadata": {
    "tags": []
   },
   "source": [
    "**File scanner**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43efa064-bf26-44b4-b482-bb5ec3c577fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScanFile(object):\n",
    "    def __init__(self, directory, prefix=None, postfix=None):\n",
    "        self.directory = directory\n",
    "        self.prefix = prefix\n",
    "        self.postfix = postfix\n",
    "\n",
    "    def scan_files(self):\n",
    "        files_list = []\n",
    "\n",
    "        for dirpath, dirnames, filenames in os.walk(self.directory):\n",
    "            ''''' \n",
    "            dirpath is a string, the path to the directory.   \n",
    "            dirnames is a list of the names of the subdirectories in dirpath (excluding '.' and '..'). \n",
    "            filenames is a list of the names of the non-directory files in dirpath. \n",
    "            '''\n",
    "            for special_file in filenames:\n",
    "                if self.postfix and self.prefix:\n",
    "                    if special_file.endswith(self.postfix) and special_file.startswith(self.prefix):\n",
    "                        files_list.append(os.path.join(dirpath, special_file))\n",
    "                elif self.postfix:\n",
    "                    if special_file.endswith(self.postfix):\n",
    "                        files_list.append(os.path.join(dirpath, special_file))\n",
    "                elif self.prefix:\n",
    "                    if special_file.startswith(self.prefix):\n",
    "                        files_list.append(os.path.join(dirpath, special_file))\n",
    "                else:\n",
    "                    files_list.append(os.path.join(dirpath, special_file))\n",
    "\n",
    "        return files_list\n",
    "\n",
    "    def scan_subdir(self):\n",
    "        subdir_list = []\n",
    "        for dirpath, dirnames, files in os.walk(self.directory):\n",
    "            subdir_list.append(dirpath)\n",
    "        return subdir_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b18275-1da6-49bd-b62d-d991857751b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Preparing training data for classifier finetune**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6206502-1531-40f8-b1f6-8ff7193b622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDD_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, augment=False):\n",
    "        subjects = []            \n",
    "        for (image, label) in zip(images, labels):\n",
    "            subject = tio.Subject(\n",
    "                mri=tio.ScalarImage(image),\n",
    "                labels=int(label),\n",
    "            )\n",
    "            subjects.append(subject)\n",
    "        self.transform()\n",
    "        if augment:\n",
    "            self.dataset = tio.SubjectsDataset(subjects, transform=self.aug_transform)\n",
    "        else:\n",
    "            self.dataset = tio.SubjectsDataset(subjects, transform=self.preproc_transform)\n",
    "            \n",
    "    def transform(self):\n",
    "        preprocess = tio.Compose([\n",
    "            tio.ToCanonical(),\n",
    "            tio.CropOrPad((176, 208, 176)),                                              # tight crop around brain\n",
    "            tio.Resample((samplespace, samplespace, samplespace)),                  # to MNI space (which is RAS+)\n",
    "            tio.RescaleIntensity(percentiles=(0.,99.5), out_min_max=(0, 1.0)),\n",
    "        ])\n",
    "        augment = tio.Compose([\n",
    "            tio.RandomAffine(scales=0.1,degrees=20,translation=5,isotropic=True,center='image'),       # random affine\n",
    "        ])\n",
    "\n",
    "        self.aug_transform = tio.Compose([preprocess, augment])\n",
    "        self.preproc_transform = preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c240491-23f7-42ac-9ed3-d5f4944a1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.utils import one_hot\n",
    "def get_loader(imagepaths, labels, batch_size=1, augment=False):\n",
    "    dataset = MDD_Dataset(images=imagepaths, labels=labels, augment=augment)\n",
    "    if augment:\n",
    "        loader = DataLoader(dataset.dataset,batch_size=batch_size,num_workers=batch_size,shuffle=True,pin_memory=pin_memory,drop_last=False)\n",
    "    else:\n",
    "        loader = DataLoader(dataset.dataset,batch_size=batch_size,num_workers=batch_size,shuffle=False,pin_memory=pin_memory)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fccb40-cb50-4fd2-8715-57693d624c1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Model Defination**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7478524c-7027-43e0-a5b6-afdea0560042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import Classifier\n",
    "from monai.networks.blocks import Convolution, ResidualUnit\n",
    "from monai.utils import ensure_tuple, ensure_tuple_rep\n",
    "from monai.networks.layers.simplelayers import Reshape\n",
    "\n",
    "class Regressor2inputs(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_shape: Sequence[int],\n",
    "        out_shape: Sequence[int],\n",
    "        channels: Sequence[int],\n",
    "        strides: Sequence[int],\n",
    "        kernel_size: Union[Sequence[int], int] = 3,\n",
    "        num_res_units: int = 2,\n",
    "        act=Act.PRELU,\n",
    "        norm=Norm.INSTANCE,\n",
    "        dropout: Optional[float] = None,\n",
    "        bias: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels, *self.in_shape = ensure_tuple(in_shape)\n",
    "        self.dimensions = len(self.in_shape)\n",
    "        self.channels = ensure_tuple(channels)\n",
    "        self.strides = ensure_tuple(strides)\n",
    "        self.out_shape = ensure_tuple(out_shape)\n",
    "        self.kernel_size = ensure_tuple_rep(kernel_size, self.dimensions)\n",
    "        self.num_res_units = num_res_units\n",
    "        self.act = act\n",
    "        self.norm = norm\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        self.net = nn.Sequential()\n",
    "\n",
    "        echannel = self.in_channels\n",
    "\n",
    "        padding = same_padding(kernel_size)\n",
    "\n",
    "        self.final_size = np.asarray(self.in_shape, dtype=int)\n",
    "        self.reshape = Reshape(*self.out_shape)\n",
    "\n",
    "        # encode stage\n",
    "        for i, (c, s) in enumerate(zip(self.channels, self.strides)):\n",
    "            layer = self._get_layer(echannel, c, s, i == len(channels) - 1)\n",
    "            echannel = c  # use the output channel number as the input for the next loop\n",
    "            self.net.add_module(\"layer_%i\" % i, layer)\n",
    "            self.final_size = calculate_out_shape(self.final_size, kernel_size, s, padding)  # type: ignore\n",
    "\n",
    "        self.final = self._get_final_layer((echannel,) + self.final_size)\n",
    "        self.fuse_weight = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
    "    def _get_layer(\n",
    "        self, in_channels: int, out_channels: int, strides: int, is_last: bool\n",
    "    ) -> Union[ResidualUnit, Convolution]:\n",
    "        layer: Union[ResidualUnit, Convolution]\n",
    "\n",
    "        if self.num_res_units > 0:\n",
    "            layer = ResidualUnit(\n",
    "                subunits=self.num_res_units,\n",
    "                last_conv_only=is_last,\n",
    "                spatial_dims=self.dimensions,\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                strides=strides,\n",
    "                kernel_size=self.kernel_size,\n",
    "                act=self.act,\n",
    "                norm=self.norm,\n",
    "                dropout=self.dropout,\n",
    "                bias=self.bias,\n",
    "            )\n",
    "        else:\n",
    "            layer = Convolution(\n",
    "                conv_only=is_last,\n",
    "                spatial_dims=self.dimensions,\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                strides=strides,\n",
    "                kernel_size=self.kernel_size,\n",
    "                act=self.act,\n",
    "                norm=self.norm,\n",
    "                dropout=self.dropout,\n",
    "                bias=self.bias,\n",
    "            )\n",
    "\n",
    "        return layer\n",
    "\n",
    "    def _get_final_layer(self, in_shape: Sequence[int]):\n",
    "        linear = nn.Linear(int(np.product(in_shape)), int(np.product(self.out_shape)))\n",
    "        return nn.Sequential(nn.Flatten(), linear)\n",
    "\n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = self.net(x1)\n",
    "        x2 = self.net(x2)\n",
    "        #x = self.final(self.fuse_weight*x1+x2)\n",
    "        x = self.final(x1+x2)\n",
    "        x = self.reshape(x)\n",
    "        return x\n",
    "\n",
    "class Classifier2inputs(Regressor2inputs):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_shape: Sequence[int],\n",
    "        classes: int,\n",
    "        channels: Sequence[int],\n",
    "        strides: Sequence[int],\n",
    "        kernel_size: Union[Sequence[int], int] = 3,\n",
    "        num_res_units: int = 2,\n",
    "        act=Act.PRELU,\n",
    "        norm=Norm.INSTANCE,\n",
    "        dropout: Optional[float] = None,\n",
    "        bias: bool = True,\n",
    "        last_act: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        super().__init__(in_shape, (classes,), channels, strides, kernel_size, num_res_units, act, norm, dropout, bias)\n",
    "\n",
    "        if last_act is not None:\n",
    "            last_act_name, last_act_args = split_args(last_act)\n",
    "            last_act_type = Act[last_act_name]\n",
    "\n",
    "            self.final.add_module(\"lastact\", last_act_type(**last_act_args))\n",
    "\n",
    "class AE2DecClf_V1(AutoEncoder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_shape: Sequence[int],\n",
    "        out_channels: int,\n",
    "        #out_channels2: int,\n",
    "        num_classes: int,\n",
    "        channels: Sequence[int],\n",
    "        strides: Sequence[int],\n",
    "        out_channels2: int = 4,\n",
    "        kernel_size: Union[Sequence[int], int] = 3,\n",
    "        up_kernel_size: Union[Sequence[int], int] = 3,\n",
    "        num_res_units: int = 0,\n",
    "        inter_channels: Optional[list] = None,\n",
    "        inter_dilations: Optional[list] = None,\n",
    "        num_inter_units: int = 2,\n",
    "        act: Optional[Union[Tuple, str]] = Act.PRELU,\n",
    "        norm: Union[Tuple, str] = Norm.INSTANCE,\n",
    "        dropout: Optional[Union[Tuple, str, float]] = None,\n",
    "        bias: bool = True,\n",
    "    ) -> None:\n",
    "\n",
    "        self.in_channels, *self.in_shape = in_shape\n",
    "        self.final_size = np.asarray(self.in_shape, dtype=int)\n",
    "\n",
    "        super().__init__(\n",
    "            spatial_dims,\n",
    "            self.in_channels,\n",
    "            out_channels,\n",
    "            channels,\n",
    "            strides,\n",
    "            kernel_size,\n",
    "            up_kernel_size,\n",
    "            num_res_units,\n",
    "            inter_channels,\n",
    "            inter_dilations,\n",
    "            num_inter_units,\n",
    "            act,\n",
    "            norm,\n",
    "            dropout,\n",
    "            bias,\n",
    "        )\n",
    "\n",
    "        padding = same_padding(self.kernel_size)\n",
    "\n",
    "        for s in strides:\n",
    "            self.final_size = calculate_out_shape(self.final_size, self.kernel_size, s, padding)  # type: ignore\n",
    "\n",
    "        linear_size = int(np.product(self.final_size)) * self.encoded_channels\n",
    "\n",
    "        self.clf = Classifier2inputs(in_shape = (self.channels[-1], *self.final_size), \n",
    "                              classes = num_classes, \n",
    "                              channels = (256,),\n",
    "                              strides = (2,), \n",
    "                              #num_res_units = 0,\n",
    "                              norm='INSTANCE', \n",
    "                              dropout=None, \n",
    "                              last_act=None)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        x = self.encode(x)\n",
    "        feature = self.intermediate(x)\n",
    "        feature1, feature2 = torch.chunk(feature,2,dim=1)\n",
    "        y = self.clf(feature1, feature2)\n",
    "        return y#mri, seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990202e-8fdb-4312-bf0c-0e1e6cc72a2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Training Function**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8e63da-4f8d-421d-aef5-7d9fc7e5e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1Loss  = torch.nn.L1Loss(reduction='sum')\n",
    "MSELoss = torch.nn.MSELoss(reduction='sum')\n",
    "BCELoss = torch.nn.BCELoss(reduction='sum')\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "dice_loss = DiceLoss(include_background=True ,to_onehot_y=True, softmax=True)\n",
    "HD95_loss = HausdorffDistanceMetric(include_background=False, distance_metric='euclidean', percentile=95, directed=False)\n",
    "#dice_loss = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "def train(model, max_epochs, learning_rate, savename):\n",
    "    model.to(device)\n",
    "    avg_train_losses = []\n",
    "    avg_train_dice_losses =[]\n",
    "    avg_train_mse_losses = []\n",
    "    avg_train_kld_losses = []\n",
    "    test_losses = []\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = []\n",
    "    threshhold = 0.6\n",
    "\n",
    "    \n",
    "    t = trange(max_epochs, leave=True, desc=\"step: 0, average train loss: ?, test loss: ?\")\n",
    "    \n",
    "    for epoch in t:\n",
    "        model.train()\n",
    "        mse_losses = []\n",
    "        dice_losses = []\n",
    "        kld_losses = []\n",
    "        epoch_losses = []\n",
    "        epoch_loss = 0\n",
    "        mse_loss = 0\n",
    "        kld_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step +=1\n",
    "            #print('\\r step:%d' % (step), end='')\n",
    "            inputs = batch_data['mri'][tio.DATA].to(device).float()\n",
    "            labels = batch_data['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "            t.set_description(f\"step: {step}\")\n",
    "        scheduler.step()\n",
    "        avg_train_losses.append(np.mean(epoch_losses))\n",
    "\n",
    "        if (epoch+1) > 80 and (epoch+1)%val_interval == 0:\n",
    "            y_prob = torch.cat(test_prob, dim=0).cpu().detach().numpy()\n",
    "            #y_pred = torch.cat(pred, dim=0).cpu().detach().numpy()\n",
    "            y_true = torch.cat(test_label, dim=0).cpu().detach().numpy()\n",
    "            y_pred =  np.array(torch.cat(test_predict, dim=0).cpu().detach().numpy()[...,1],dtype=int)\n",
    "            epoch_report = classification_report(y_true, y_pred, output_dict = True,target_names=['CN', 'AD'],zero_division=0)\n",
    "\n",
    "            metric = epoch_report['accuracy']\n",
    "            if ((metric > best_metric+0.005) and (metric > threshhold)) or ((epoch+1)%30 == 0):\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                best_model_name = savename+'_epoch%02i_acc%.3f.pth' % (best_metric_epoch,best_metric)\n",
    "                torch.save(model.state_dict(), best_model_name)\n",
    "                print(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "            if (metric > 0.9):\n",
    "                break\n",
    "        if len(test_losses)>0:\n",
    "            t.set_postfix(avg_train_losses=avg_train_losses[-1])\n",
    "    return model, best_model_name, avg_train_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733aa6e4-ac0f-443c-b8c4-84deb2df9bee",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Testing Function**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a3bb1e-01c1-4dea-a86c-a2e19c8aaade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    min_v_loss = np.inf\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "\n",
    "    print(\"-\" * 10)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    pred = []\n",
    "    prob = []\n",
    "    label = []\n",
    "    predict= []\n",
    "\n",
    "    num_correct = 0.0\n",
    "    metric_count = 0\n",
    "    #for test_data in tqdm(train_loader):\n",
    "    for test_data in tqdm(test_loader):\n",
    "        test_inputs = test_data['mri'][tio.DATA].to(device)\n",
    "        test_labels = test_data['labels']\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(test_inputs.float())\n",
    "        outprob = F.softmax(test_outputs, dim=1)\n",
    "        prob.append(outprob)\n",
    "        pred.append(outprob.max(dim=1)[1])\n",
    "        predict.append(torch.where(outprob>0.5,torch.ones_like(outprob),torch.zeros_like(outprob)))\n",
    "        label.append(test_labels)\n",
    "\n",
    "    y_prob = torch.cat(prob, dim=0).cpu().detach().numpy()\n",
    "    #y_pred = torch.cat(pred, dim=0).cpu().detach().numpy()\n",
    "    y_true = torch.cat(label, dim=0).cpu().detach().numpy()\n",
    "    y_pred =  np.array(torch.cat(predict, dim=0).cpu().detach().numpy()[...,1],dtype=int)\n",
    "    #y_predict = np.where(y_prob < 0.5, 0, 1) \n",
    "    #print(y_prob)\n",
    "    print(y_pred)\n",
    "    #print(y_predict)\n",
    "    print(y_true)\n",
    "\n",
    "    AUC = roc_auc_score(y_true,y_prob[:,1]) *100\n",
    "    #AUC = roc_auc_score(y_true,y_pred) *100\n",
    "    MCC = matthews_corrcoef(y_true, y_pred)*100\n",
    "    confus_mtrx = confusion_matrix(y_true, y_pred).ravel() #sample_weight=sw ravel:flatten\n",
    "    #SPE  = confus_mtrx[0]/(confus_mtrx[0]+confus_mtrx[1])\n",
    "    epoch_report = classification_report(y_true, y_pred, output_dict = True,target_names=['CND', 'CI'],zero_division=0)\n",
    "    return AUC, MCC, epoch_report, confus_mtrx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc810ae-fcc6-401f-8abb-1ec1ba06840e",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Training and Test Process for 5 Folds**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3beaf7bd-ad44-4dae-bedb-1971d94a634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained auto encoder:./models/AE2DecPriorV1_mri_seg_epoch30_diceloss6.76_l1loss153245.66.pth\n",
      "Training start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 88:   0%|          | 0/90 [00:30<?, ?it/s]                                    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_621901/2358982337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0msavename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msavefile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-fold'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_train_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Finish!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_621901/3383189769.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, max_epochs, learning_rate, savename)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "im_shape = (1,176,208,176)\n",
    "test_AUC =[]\n",
    "test_ACC =[]\n",
    "test_PRE =[]\n",
    "test_SEN =[]\n",
    "test_SPE =[]\n",
    "test_F1s =[]\n",
    "test_MCC =[]\n",
    "\n",
    "finetuned = True\n",
    "preAEmodelname = 'AE2DecPriorV1'\n",
    "savefile = savedir+modelname+'_'+preAEmodelname+'_'+'fintune_cnd-ci'\n",
    "logfile = savefile.replace(trained_path,logdir_path)\n",
    "\n",
    "out_ch = 1        \n",
    "if preAEmodelname == 'AE2DecPriorV1' or preAEmodelname == 'AE2DecPriorV1_W':\n",
    "    preAE_model = './models/'+'AE2DecPriorV1_mri_seg_epoch30_diceloss6.76_l1loss153245.66'+'.pth'\n",
    "elif preAEmodelname == 'AE2DecPriorV1_adcn':\n",
    "    preAE_model = './models/'+'ADNI_adcn_AE2DecClf_V1_pretrain_adcn_epoch100'+'.pth'\n",
    "\n",
    "for k in range(5):\n",
    "    model = AE2DecClf_V1(\n",
    "        spatial_dims=3,\n",
    "        in_shape=im_shape,\n",
    "        num_classes=categories,\n",
    "        out_channels=1,#mri\n",
    "        channels=(64,128,256,512),\n",
    "        strides=(2,2,2,2),\n",
    "        inter_channels=(512,512*2),\n",
    "        inter_dilations=(1, 1),\n",
    "        num_inter_units=2,\n",
    "    )\n",
    "\n",
    "    if finetuned:\n",
    "        pre_model = preAE_model\n",
    "        print('loading pretrained auto encoder:'+pre_model)\n",
    "        model.load_state_dict(torch.load(pre_model), strict = False)\n",
    "        model_dict = model.state_dict()\n",
    "        #print(model_dict.keys())\n",
    "        for name, p in model.named_parameters():\n",
    "            #print(name)\n",
    "            if name.startswith('encode') or name.startswith('intermediate'): #or name.startswith('decode'):\n",
    "            #if name.startswith('encode'): #or name.startswith('decode'):\n",
    "                p.requires_grad = False\n",
    "           # print(name, p.requires_grad)\n",
    "    #torchsummary.summary(model.cuda(),im_shape)\n",
    "\n",
    "    train_listfile = './data/LLD/LLD_labels_cnd_ci_train_balenced__'+str(k)+'.csv'\n",
    "    test_listfile = './data/LLD/LLD_labels_cnd_ci_test__'+str(k)+'.csv'\n",
    "    train_csv_data = pd.read_csv(train_listfile)  # 读取训练数据\n",
    "    test_csv_data = pd.read_csv(test_listfile)  # 读取训练数据\n",
    "\n",
    "    train_mri_path_list = train_csv_data['mripath'].values.tolist()\n",
    "    train_label_list    = train_csv_data['labels'].values.tolist()\n",
    "    test_mri_path_list = test_csv_data['mripath'].values.tolist()\n",
    "    test_label_list    = test_csv_data['labels'].values.tolist()\n",
    "\n",
    "    train_loader = get_loader(train_mri_path_list,train_label_list, batch_size=2, augment=True)\n",
    "    test_loader  = get_loader(test_mri_path_list,test_label_list, batch_size=2)\n",
    "\n",
    "    print('Training start!')\n",
    "    max_epochs = 90\n",
    "    learning_rate = 1e-4\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    savename = savefile+'-fold'+str(k)\n",
    "    model, best_model_name, avg_train_losses = train(model, max_epochs, learning_rate, savename)\n",
    "    print(\"Training Finish!\")\n",
    "\n",
    "    print('Testing start!')\n",
    "    AUC, MCC, epoch_report, confus_mtrx = test(model, test_loader)\n",
    "    ACC = epoch_report['accuracy']*100\n",
    "    SPE = epoch_report['CND']['recall']*100\n",
    "    PRE = epoch_report['CI']['precision']*100\n",
    "    SEN = epoch_report['CI']['recall']*100\n",
    "    F1s = epoch_report['CI']['f1-score']*100\n",
    "    test_AUC.append(AUC)\n",
    "    test_ACC.append(ACC)\n",
    "    test_PRE.append(PRE)\n",
    "    test_SEN.append(SEN)\n",
    "    test_SPE.append(SPE)\n",
    "    test_F1s.append(F1s)\n",
    "    test_MCC.append(MCC)\n",
    "    with open(logfile+'.txt', 'a') as f:\n",
    "        f.writelines('fold'+str(k)+'\\n')\n",
    "        f.writelines(best_model_name+'\\n')\n",
    "        f.writelines(f'AUC:{AUC:.2f}, ACC:{ACC:.2f}, PRE:{PRE:.2f}, SEN:{SEN:.2f}, SPE:{SPE:.2f}, F1S:{F1s:.2f}, MCC:{MCC:.2f}\\n')\n",
    "    print(f'AUC:{AUC:.2f}, ACC:{ACC:.2f}, PRE:{PRE:.2f}, SEN:{SEN:.2f}, SPE:{SPE:.2f}, F1S:{F1s:.2f}, MCC:{MCC:.2f}')\n",
    "    print(f'{AUC:.2f}\\t{ACC:.2f}\\t{PRE:.2f}\\t{SEN:.2f}\\t{SPE:.2f}\\t{F1s:.2f}\\t{MCC:.2f}')\n",
    "    print('Testing finish!')\n",
    "\n",
    "mean_AUC =round(np.mean(test_AUC),2)\n",
    "mean_ACC =round(np.mean(test_ACC),2)\n",
    "mean_PRE =round(np.mean(test_PRE),2)\n",
    "mean_SEN =round(np.mean(test_SEN),2)\n",
    "mean_SPE =round(np.mean(test_SPE),2)\n",
    "mean_F1s =round(np.mean(test_F1s),2)\n",
    "mean_MCC =round(np.mean(test_MCC),2)\n",
    "\n",
    "std_AUC =round(np.std(test_AUC,ddof=1),2)\n",
    "std_ACC =round(np.std(test_ACC,ddof=1),2)\n",
    "std_PRE =round(np.std(test_PRE,ddof=1),2)\n",
    "std_SEN =round(np.std(test_SEN,ddof=1),2)\n",
    "std_SPE =round(np.std(test_SPE,ddof=1),2)\n",
    "std_F1s =round(np.std(test_F1s,ddof=1),2)\n",
    "std_MCC =round(np.std(test_MCC,ddof=1),2)\n",
    "log1 = f'AUC:{mean_AUC}\\xB1{std_AUC}, ACC:{mean_ACC}\\xB1{std_ACC}, PRE:{mean_PRE}\\xB1{std_PRE}, SEN:{mean_SEN}\\xB1{std_SEN}, SPE:{mean_SPE}\\xB1{std_SPE}, F1S:{mean_F1s}\\xB1{std_F1s}, MCC:{mean_MCC}\\xB1{std_MCC}\\n'\n",
    "log2 = f'{mean_AUC}\\xB1{std_AUC}\\t{mean_ACC}\\xB1{std_ACC}\\t{mean_PRE}\\xB1{std_PRE}\\t{mean_SEN}\\xB1{std_SEN}\\t{mean_SPE}\\xB1{std_SPE}\\t{mean_F1s}\\xB1{std_F1s}\\t{mean_MCC}\\xB1{std_MCC}\\n'\n",
    "\n",
    "log3 = f'&{mean_AUC:.2f}\\xB1{std_AUC:.2f} &{mean_ACC:.2f}\\xB1{std_ACC:.2f} &{mean_SEN:.2f}\\xB1{std_SEN:.2f} &{mean_SPE:.2f}\\xB1{std_SPE:.2f} &{mean_F1s:.2f}\\xB1{std_F1s:.2f}\\n'\n",
    "log4 = f'&{mean_AUC:.1f}({std_AUC:.1f}) &{mean_ACC:.1f}({std_ACC:.1f}) &{mean_SEN:.1f}({std_SEN:.1f}) &{mean_SPE:.1f}({std_SPE:.1f}) &{mean_F1s:.1f}({std_F1s:.1f})\\n'\n",
    "\n",
    "with open(logfile+'.txt', 'a') as f:\n",
    "    f.writelines(log1)\n",
    "    f.writelines(log2)\n",
    "    f.writelines(log3)\n",
    "    f.writelines(log4)\n",
    "\n",
    "print(log1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
